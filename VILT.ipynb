{"cells":[{"cell_type":"markdown","metadata":{"id":"GmW1q4ngnMVN"},"source":["# Google Drive Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":785,"status":"ok","timestamp":1682987546703,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"v17rbm1RiWfc","outputId":"ad2802f2-1f6d-4a4a-97b1-ec2154374a0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# NOTE: To be able to access the shared files, you need to go to Drive and click\n","# \"Add shortcut to Drive\" on the options for the shared folder to be able to access it when mounted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExCAwvudinTK"},"outputs":[],"source":["# Paths to the \"Project Code\" folder\n","path_andrew = \"/content/gdrive/MyDrive/CS 7643/Project/Project Code\"\n","path_gillian = \"/content/gdrive/MyDrive/CS 7643/Project Code\"\n","path_blake = \"/content/gdrive/MyDrive/CS 7643/Project Code\"\n","path_isaac = \"/content/gdrive/MyDrive/classes/CS 7643/Project Code\"\n","path_bryan = \"/content/gdrive/MyDrive/Georgia Tech/CS 7643/CS 7643/Project Code\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":539,"status":"ok","timestamp":1682987547237,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"74izcRhflvEJ","outputId":"85d889d0-0f37-466e-d30d-c3d8a7fd29b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/.shortcut-targets-by-id/1lmYZ9dBUQsLKZApoHNFRjbtE_VA1kGF4/CS 7643/Project Code\n"]}],"source":["# change this to your path when running\n","path = path_isaac\n","%cd {path}"]},{"cell_type":"markdown","metadata":{"id":"96bZw7EEnP4I"},"source":["# Imports/Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18375,"status":"ok","timestamp":1682987565605,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"MVW58P_MjCl3","outputId":"be88c951-eaf9-4369-fb91-9b9fe3824097"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.6)\n","Requirement already satisfied: torchtnt>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from torcheval) (0.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.0.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (1.22.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2023.4.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (5.9.5)\n","Requirement already satisfied: pyre-extensions in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (0.0.30)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (4.65.0)\n","Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions->torchtnt>=0.0.5->torcheval) (0.8.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (16.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval) (1.0.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n"]}],"source":["# pip installs\n","!pip install transformers\n","!pip install torcheval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7f5qclwjHMZ"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torcheval.metrics.functional import binary_auroc\n","\n","# data\n","from HMDataset import HMDataset, HMDataset_H5\n","\n","# model\n","from transformers import ViltProcessor, ViltModel\n","from ClassificationHead import ViltHead\n","\n","# general\n","from PIL import Image\n","import requests\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549,"status":"ok","timestamp":1682987586420,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"UP0RU_UBmnOB","outputId":"c2059298-fa5d-44ef-bb3f-db60ed91cb00"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.0+cu118\n","True\n"]}],"source":["# gpu check\n","print(torch.__version__)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device=='cuda')"]},{"cell_type":"markdown","metadata":{"id":"x-O1GOgtncNx"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5R7ndqzePAmw"},"outputs":[],"source":["# Hyperparameters\n","batch_size = 64\n","lr = 1e-4\n","momentum = 0.9\n","weight_decay = 1e-5\n","epochs = 10\n","dropout = 0.1\n","\n","output_file_name = \"vilt_head\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obHCiMCgpcx1"},"outputs":[],"source":["# create PyTorch dataset from the given files/directories\n","# make sure paths are correct\n","\n","# each sample has keys: \"id\", \"image\", \"label\", and \"text\"\n","transform_h5 = transforms.ToTensor() # everything in HDF5 is already pre-resized to 256 x 256\n","\n","train_dataset = HMDataset_H5(h5_file=path + \"/training_db.h5\", transform=transform_h5)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n","\n","# validation\n","validate_dataset = HMDataset_H5(h5_file=path + \"/validation_db.h5\", transform=transform_h5)\n","validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n","\n","# testing\n","test_dataset = HMDataset_H5(h5_file=path + \"/test_db.h5\", transform=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HLfnX5wtwf_"},"outputs":[],"source":["def get_metrics_and_losses(losses, predictions, labels):\n","  average_loss = losses.mean().item()\n","  accuracy = (predictions == labels).sum().item() / labels.numel()\n","  auroc = binary_auroc(predictions, labels)\n","\n","  return average_loss, accuracy, auroc"]},{"cell_type":"markdown","metadata":{"id":"LuaMOmDDnI9f"},"source":["# VILT Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16576,"status":"ok","timestamp":1682987603717,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"kNAJU_ycnIur","outputId":"21d5cf0e-4f11-4bdd-95e0-372987d3e63c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at dandelin/vilt-b32-mlm were not used when initializing ViltModel: ['mlm_score.transform.LayerNorm.bias', 'mlm_score.bias', 'mlm_score.decoder.weight', 'mlm_score.transform.LayerNorm.weight', 'mlm_score.transform.dense.bias', 'mlm_score.transform.dense.weight']\n","- This IS expected if you are initializing ViltModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViltModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["ViltConfig {\n","  \"_name_or_path\": \"dandelin/vilt-b32-mlm\",\n","  \"architectures\": [\n","    \"ViltForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"image_size\": 384,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_image_length\": -1,\n","  \"max_position_embeddings\": 40,\n","  \"modality_type_vocab_size\": 2,\n","  \"model_type\": \"vilt\",\n","  \"num_attention_heads\": 12,\n","  \"num_channels\": 3,\n","  \"num_hidden_layers\": 12,\n","  \"num_images\": -1,\n","  \"patch_size\": 32,\n","  \"qkv_bias\": true,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n"]},{"data":{"text/plain":["ViltModel(\n","  (embeddings): ViltEmbeddings(\n","    (text_embeddings): TextEmbeddings(\n","      (word_embeddings): Embedding(30522, 768)\n","      (position_embeddings): Embedding(40, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (patch_embeddings): ViltPatchEmbeddings(\n","      (projection): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n","    )\n","    (token_type_embeddings): Embedding(2, 768)\n","    (dropout): Dropout(p=0.0, inplace=False)\n","  )\n","  (encoder): ViltEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x ViltLayer(\n","        (attention): ViltAttention(\n","          (attention): ViltSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (output): ViltSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (intermediate): ViltIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): ViltOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","        )\n","        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  (pooler): ViltPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Get Pretrained Model\n","\n","processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-coco\")\n","\n","\n","     \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = ViltModel.from_pretrained(\"dandelin/vilt-b32-mlm\")\n","print(model.config)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiDAK1w2eBev"},"outputs":[],"source":["head = ViltHead(dropout=dropout)\n","head.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(head.parameters(), lr=lr, weight_decay=weight_decay)"]},{"cell_type":"markdown","metadata":{"id":"NVgrUoFBMMc6"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1412000,"status":"ok","timestamp":1682990252150,"user":{"displayName":"Isaac Dale","userId":"03595123198176106545"},"user_tz":240},"id":"enSUSNu2O3ML","outputId":"e9fa1290-946f-499e-9d09-9542e8fbc78e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1 Training: 100%|██████████| 132/132 [04:32<00:00,  2.07s/it]\n","Epoch 1 Training: 100%|██████████| 7/7 [00:13<00:00,  1.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","New head saved at epoch 1\n","Epoch 1\n","Training Loss: 0.6300. Validation Loss: 0.7973. \n","Training Accuracy: 0.6481. Validation Accuracy: 0.5089. \n","Training AUROC: 0.5107. Validation AUROC: 0.5023. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 Training: 100%|██████████| 132/132 [04:12<00:00,  1.92s/it]\n","Epoch 2 Training: 100%|██████████| 7/7 [00:13<00:00,  1.96s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","New head saved at epoch 2\n","Epoch 2\n","Training Loss: 0.6012. Validation Loss: 0.6969. \n","Training Accuracy: 0.6732. Validation Accuracy: 0.5379. \n","Training AUROC: 0.5715. Validation AUROC: 0.5324. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 Training: 100%|██████████| 132/132 [04:13<00:00,  1.92s/it]\n","Epoch 3 Training: 100%|██████████| 7/7 [00:13<00:00,  1.97s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","New head saved at epoch 3\n","Epoch 3\n","Training Loss: 0.5879. Validation Loss: 0.6936. \n","Training Accuracy: 0.6913. Validation Accuracy: 0.5446. \n","Training AUROC: 0.6137. Validation AUROC: 0.5426. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 Training: 100%|██████████| 132/132 [04:11<00:00,  1.90s/it]\n","Epoch 4 Training: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","New head saved at epoch 4\n","Epoch 4\n","Training Loss: 0.5759. Validation Loss: 0.6697. \n","Training Accuracy: 0.7016. Validation Accuracy: 0.5737. \n","Training AUROC: 0.6327. Validation AUROC: 0.5709. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 Training: 100%|██████████| 132/132 [04:11<00:00,  1.90s/it]\n","Epoch 5 Training: 100%|██████████| 7/7 [00:13<00:00,  1.96s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5\n","Training Loss: 0.5714. Validation Loss: 0.7477. \n","Training Accuracy: 0.7049. Validation Accuracy: 0.5402. \n","Training AUROC: 0.6407. Validation AUROC: 0.5342. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6 Training: 100%|██████████| 132/132 [04:06<00:00,  1.87s/it]\n","Epoch 6 Training: 100%|██████████| 7/7 [00:13<00:00,  1.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6\n","Training Loss: 0.5607. Validation Loss: 0.7038. \n","Training Accuracy: 0.7135. Validation Accuracy: 0.5692. \n","Training AUROC: 0.6535. Validation AUROC: 0.5660. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7 Training: 100%|██████████| 132/132 [04:02<00:00,  1.84s/it]\n","Epoch 7 Training: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7\n","Training Loss: 0.5509. Validation Loss: 0.7198. \n","Training Accuracy: 0.7191. Validation Accuracy: 0.5692. \n","Training AUROC: 0.6628. Validation AUROC: 0.5668. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8 Training: 100%|██████████| 132/132 [04:02<00:00,  1.84s/it]\n","Epoch 8 Training: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8\n","Training Loss: 0.5455. Validation Loss: 0.7241. \n","Training Accuracy: 0.7249. Validation Accuracy: 0.5536. \n","Training AUROC: 0.6697. Validation AUROC: 0.5536. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9 Training: 100%|██████████| 132/132 [04:04<00:00,  1.86s/it]\n","Epoch 9 Training: 100%|██████████| 7/7 [00:13<00:00,  1.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9\n","Training Loss: 0.5375. Validation Loss: 0.8332. \n","Training Accuracy: 0.7314. Validation Accuracy: 0.5692. \n","Training AUROC: 0.6793. Validation AUROC: 0.5581. \n","-----------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10 Training: 100%|██████████| 132/132 [04:07<00:00,  1.87s/it]\n","Epoch 10 Training: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10\n","Training Loss: 0.5340. Validation Loss: 0.6895. \n","Training Accuracy: 0.7320. Validation Accuracy: 0.5781. \n","Training AUROC: 0.6796. Validation AUROC: 0.5641. \n","-----------------------------------\n"]}],"source":["max_validation_auroc = 0\n","for e in range(epochs):\n","\n","  # training\n","  train_losses = torch.zeros(len(train_dataloader)).to(device)\n","  train_predictions = torch.Tensor().to(device)\n","  train_labels = torch.Tensor().to(device)\n","\n","  model.train()\n","  head.train()\n","  for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Epoch \" + str(e+1) + \" Training\"):\n","\n","    # get inputs\n","    text = data['text']\n","    image = list(data['image'].detach().numpy())\n","    labels = data['label'].to(device).to(torch.int64)\n","\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","\n","    # VILT base model\n","    inputs = processor(image, text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","    bt_outputs = model(**inputs)\n","    pooled_outputs = bt_outputs[\"pooler_output\"]\n","\n","    # classification head\n","    scores = torch.squeeze(head(pooled_outputs))\n","    predictions = scores.argmax(dim=-1)\n","\n","    # backprop\n","    loss = criterion(scores, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # track values for metric logging\n","    train_losses[i] = loss\n","    train_predictions = torch.cat((train_predictions, predictions))\n","    train_labels = torch.cat((train_labels, labels))\n","\n","    train_average_loss, train_accuracy, train_auroc = get_metrics_and_losses(train_losses, train_predictions, train_labels)\n","\n","  # validation\n","  validate_losses = torch.zeros(len(validate_dataloader)).to(device)\n","  validate_predictions = torch.Tensor().to(device)\n","  validate_labels = torch.Tensor().to(device)\n","  model.eval()\n","  head.eval()\n","  with torch.no_grad():\n","    for i, data in tqdm(enumerate(validate_dataloader), total=len(validate_dataloader), desc=\"Epoch \" + str(e+1) + \" Training\"):\n","\n","      # get inputs\n","      text = data['text']\n","      image = list(data['image'].detach().numpy())\n","      labels = data['label'].to(device).to(torch.int64)\n","\n","      # VILT base model\n","      inputs = processor(image, text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","      bt_outputs = model(**inputs)\n","      pooled_outputs = bt_outputs[\"pooler_output\"]\n","      # classification head\n","      scores = torch.squeeze(head(pooled_outputs))\n","      predictions = scores.argmax(dim=-1)\n","\n","      # loss\n","      loss = criterion(scores, labels)\n","\n","      # track values for metric logging\n","      validate_losses[i] = loss\n","      validate_predictions = torch.cat((validate_predictions, predictions), dim=0)\n","      validate_labels = torch.cat((validate_labels, labels), dim=0)\n","      \n","\n","  validate_average_loss, validate_accuracy, validate_auroc = get_metrics_and_losses(validate_losses, validate_predictions, validate_labels)\n","  if validate_auroc > max_validation_auroc:\n","    max_validation_auroc = validate_auroc\n","    torch.save(head.state_dict(), \"heads/\"+output_file_name+\".pt\")\n","    print(\"\\nNew head saved at epoch \" + str(e+1))\n","    \n","  print(\"Epoch %d\" % (e+1))\n","  print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (train_average_loss, validate_average_loss))\n","  print(\"Training Accuracy: %.4f. Validation Accuracy: %.4f. \" % (train_accuracy, validate_accuracy))\n","  print(\"Training AUROC: %.4f. Validation AUROC: %.4f. \" % (train_auroc, validate_auroc))\n","  print(\"-----------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvX2erQl8jF5","outputId":"87599bd6-8b74-43e6-dc97-b21b628d9533"},"outputs":[{"name":"stderr","output_type":"stream","text":["Test:  12%|█▎        | 1/8 [00:03<00:24,  3.52s/it]"]}],"source":["def run_model(model, processor, head, criterion, text, image, labels):\n","\n","    # model\n","    inputs = processor(text=text, images=image, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","    outputs = model(**inputs)\n","\n","    # head\n","    pooled_outputs = bt_outputs[\"pooler_output\"]\n","    # classification head\n","    scores = torch.squeeze(head(pooled_outputs))\n","    predictions = scores.argmax(dim=-1)\n","    # loss\n","    loss = criterion(scores, labels)\n","    return loss, predictions\n","\n","# test\n","def test(model, processor, head, criterion, test_dataloader):\n","    model.eval()\n","    best_head.eval()\n","    test_losses = torch.zeros(len(test_dataloader)).to(device)\n","    test_predictions = torch.Tensor().to(device)\n","    test_labels = torch.Tensor().to(device)\n","    with torch.no_grad():\n","        for i,data in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Test\", position=0, leave=True):\n","            # get inputs\n","            text = data['text']\n","            image = data['image'].to(device)\n","            labels = data['label'].to(device).to(torch.int64)\n","            \n","            # run model\n","            loss, predictions = run_model(model, processor, head, criterion, text, image, labels)\n","\n","            # track values for metric logging\n","            test_losses[i] = loss\n","            test_predictions = torch.cat((test_predictions, predictions), dim=0)\n","            test_labels = torch.cat((test_labels, labels), dim=0)\n","        \n","    # log loss and metrics\n","    test_average_loss, test_accuracy, test_auroc = get_metrics_and_losses(test_losses, test_predictions, test_labels)\n","    print(\"\\n     Testing Loss: %.4f. \" % (test_average_loss))\n","    print(\"     Testing Accuracy: %.4f. \" % (test_accuracy))\n","    print(\"     Testing AUROC: %.4f. \" % (test_auroc))\n","\n","    return test_average_loss, test_accuracy, test_auroc\n","\n","# load best head\n","best_head = ViltHead(dropout=dropout)\n","best_head.load_state_dict(torch.load('heads/'+output_file_name+\".pt\"))\n","best_head.to(device)\n","\n","# test\n","test(model, processor, best_head, criterion, test_dataloader)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["3hFHzLmi_SAO"],"provenance":[{"file_id":"16vdPiwewpF6MrAbBTVaSUU7wch8zeAEM","timestamp":1681692604245}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}